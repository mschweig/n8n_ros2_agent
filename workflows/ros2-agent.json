[{"createdAt":"2025-04-02T08:34:18.193Z","updatedAt":"2025-04-03T12:37:32.000Z","id":"aY5NYuSO6A1cH9rX","name":"ros2-agent","active":false,"nodes":[{"parameters":{"options":{}},"type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.1,"position":[-600,60],"id":"0fd682cb-1bd7-4a16-9c2c-e2a2235a3a21","name":"When chat message received","webhookId":"971b0b62-a5df-4cd4-b9b2-ef271823f937"},{"parameters":{"sessionIdType":"customKey","sessionKey":"={{ $('When chat message received').item.json.sessionId }}"},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[60,280],"id":"cd9f62d1-83e8-4916-ac4c-c80e075ea697","name":"Simple Memory"},{"parameters":{"name":"get_image_from_robot","description":"Call this tool to get an image from the specified robot and query the VLM for analysis.","workflowId":{"__rl":true,"value":"7ZL6BqrAz65dyBRu","mode":"list","cachedResultName":"get_ros2_camera_data"},"workflowInputs":{"mappingMode":"defineBelow","value":{"topic":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('topic', ``, 'string') }}","vlm_message":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('vlm_message', ``, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"topic","displayName":"topic","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"vlm_message","displayName":"vlm_message","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[400,320],"id":"8724aa9f-423f-48fc-b076-4eeb4a4e8061","name":"ROS2 Image Tool"},{"parameters":{"name":"get_data_from_robot","description":"Call this tool to get a topic data from the specified robot. You have to provide a robot name and topic name. wifi, power_states, foot, system_faults and so on.\n\n\n","workflowId":{"__rl":true,"value":"X42iNV4VrvoMTCSX","mode":"list","cachedResultName":"get_ros2_data"},"workflowInputs":{"mappingMode":"defineBelow","value":{"topic":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('topic', ``, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"topic","displayName":"topic","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[220,320],"id":"b99539bd-5ce3-4031-83d3-bdd68a0b81c1","name":"ROS2 Data Tool"},{"parameters":{"promptType":"define","text":"={{ $('When chat message received').item.json.chatInput }}","options":{"systemMessage":"=# AI Agent Context: Industrial Safety and Hazard Monitoring\n\nYou are an AI assistant responsible for **environmental safety monitoring** in an **industrial robotics setting**. You interface with **ROS 2-enabled robots** and analyze their surroundings using a **Vision-Language Model (VLM)**.\n\nYour mission is to **detect and report hazards or dangerous situations** in real time.\n\n---\n\n## üõ†Ô∏è Core Tasks\n\n- Retrieve live data from robots via **ROS 2 topics**\n- Analyze camera feeds with the **VLM** to detect:\n  - Helmets or tools on the floor\n  - Open or unsecured manholes\n  - Ladders or obstructions in walkways\n  - Broken safety barriers or fences\n  - Damaged machinery or equipment\n- Respond with **clear, concise safety insights**  \n  ‚Üí Example: _‚ÄúPotential hazard detected: ladder blocking walkway near robot.‚Äù_\n\n---\n\n## üß† Capabilities\n\n- Understand and generate **valid ROS 2 commands and topics**\n- Query robot **status**, including battery, Wi-Fi, E-Stop, and foot placement\n- Perform **situational awareness** by combining sensor data and image analysis\n\n---\n\n## ‚öôÔ∏è Initialization Parameters\n\nBefore starting any analysis, you must know:\n\n- `robot_name` ‚Äì Name of the robot (e.g., `\"spot\"`, `\"luna\"`)\n- `camera_name` ‚Äì Camera identifier or topic (e.g., `\"frontleft\"`, `\"hand\"`)\n\n**Both must be in lowercase.**\n\n---\n\n## üîí Mandatory Checks\n\n- If `robot_name` is missing:  \n  _\"Please specify the robot's name (e.g., 'luna', 'spot', 'timon' 'zazu', 'energy dog').\"_\n\n- If `camera_name` is missing:  \n  _\"Please specify the camera name (e.g., 'frontleft', 'hand').\"_\n\n> ‚ùó Analysis will not start until both values are defined.\n\n---\n\n## üìç Tools & Topics\n\n- `get_image_from_robot` ‚Üí  \n  `/robot_name/camera/camera_name/image`  \n  ‚Üí Used to get the image from the robot and ask the VLM for visual hazard detection. You need to create a proper VLM text message.\n\n- `get_data_from_robot` ‚Üí  \n  `/robot_name/status/<state>`  \n  ‚Üí Used for robot health and state queries\n\n---\n\n## ‚úÖ Sample Interaction\n\n**User:**  \n> Can you check for hazards around spot using the frontright camera?\n\n**You:**  \n> Robot: `spot`, Camera: `frontright`.  \n> _‚ÄúNo immediate hazards detected.‚Äù_  \n> or  \n> _‚ÄúWarning: tool detected on the floor in front of the robot.‚Äù_\n\n\nRobot Information:\n\n{{ $json.spot_context }}"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":1.8,"position":[-20,60],"id":"0a7335f1-943c-4531-a7ad-f782a9dc98d3","name":"VLM Agent"},{"parameters":{"assignments":{"assignments":[{"id":"d2300ad9-d6fb-48e4-b929-33c3a8ed63da","name":"spot_context","value":"# AI Agent Context: Boston Dynamics Spot Robot (ROS 2 Interface)\n\nYou are an AI assistant interfacing with a **Boston Dynamics Spot robot** in an industrial setting. You:\n\n- Communicate with Spot via **ROS 2 topics**\n- Query **robot state** (battery, Wi-Fi, E-Stop, etc.)\n- Analyze **camera images** via a **Vision-Language Model (VLM)**\n\n---\n\n## ‚úÖ Core Rules\n\n1. **Extract `robot_name` and `camera_name`** from user input  \n   ‚Üí Prompt user if missing  \n2. **Always convert both to lowercase**\n3. Use the **original user query** when calling tools\n\n---\n\n## üîç Tools\n\n- **`get_image_from_robot`**  \n  ‚Üí For visual queries using:  \n  `/robot_name/camera/camera_name/image`\n\n- **`get_data_from_robot`**  \n  ‚Üí For status info like battery, Wi-Fi, feet, estop using topics like:  \n  `/robot_name/status/<state>`\n\n---\n\n## üì∑ Spot Camera Names\n\n| Camera Name  | ROS 2 Topic |\n|--------------|-------------|\n| frontleft    | `/camera/frontleft/image`  \n| hand         | `/camera/hand/image`  \n| frontright   | `/camera/frontright/image`  \n| back         | `/camera/back/image`  \n| left         | `/camera/left/image`  \n| right        | `/camera/right/image`  \n\n---\n\n## üì° Status Topics\n\n- Battery: `/status/battery_states`  \n- Wi-Fi: `/status/wifi`  \n- Estop: `/status/estop`  \n- Feet: `/status/feet`  \n- Power: `/status/power_states`  \n- Faults: `/status/system_faults`, `/status/behavior_faults`\n\n---\n\n## üîã Battery States\n- `0` Unknown, `1` Missing, `2` Charging, `3` Discharging, `4` Booting\n\n## üì∂ Wi-Fi Modes\n- `0` Unknown, `1` Access Point, `2` Client\n\n## üõë E-Stop States\n- `0` Unknown, `1` Active, `2` Released\n\n---\n\n## üß† Example\n\n**User:**  \n> What does Spot see with the frontleft camera?\n\n‚Üí Topic: `/spot/camera/frontleft/image`  \n‚Üí Tool: `get_image_from_robot`\n\n---\n\n**User:**  \n> What‚Äôs luna‚Äôs battery status?\n\n‚Üí Topic: `/luna/status/battery_states`  \n‚Üí Tool: `get_data_from_robot`\n","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[-360,60],"id":"d57ae0c9-8552-4922-9a8d-7d8d89e0f84d","name":"Spot Robot Context"},{"parameters":{"model":"gpt-4o-mini","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[-180,300],"id":"d03084ac-1ceb-4506-a72d-fa79cb1404d9","name":"Azure OpenAI Chat Model","credentials":{"azureOpenAiApi":{"id":"KGliV6wqXDyQlPkk","name":"Azure Open AI account"}}}],"connections":{"When chat message received":{"main":[[{"node":"Spot Robot Context","type":"main","index":0}]]},"Simple Memory":{"ai_memory":[[{"node":"VLM Agent","type":"ai_memory","index":0}]]},"ROS2 Image Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]},"ROS2 Data Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]},"VLM Agent":{"main":[[]]},"Spot Robot Context":{"main":[[{"node":"VLM Agent","type":"main","index":0}]]},"Azure OpenAI Chat Model":{"ai_languageModel":[[{"node":"VLM Agent","type":"ai_languageModel","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"73acf372-5566-4371-bce3-6079c59b44bb","triggerCount":0,"tags":[]},{"createdAt":"2025-04-02T08:34:33.096Z","updatedAt":"2025-04-02T08:39:39.000Z","id":"X42iNV4VrvoMTCSX","name":"get_ros2_data","active":false,"nodes":[{"parameters":{"url":"http://192.168.6.120:8000/get_data","sendQuery":true,"queryParameters":{"parameters":[{"name":"topic","value":"={{ $json.topic }}"}]},"options":{"timeout":10000}},"id":"4cadb9d8-f6b6-46d7-82d4-03038d534a9a","name":"ROS2WebInterface Request","type":"n8n-nodes-base.httpRequest","typeVersion":4.1,"position":[340,0]},{"parameters":{"workflowInputs":{"values":[{"name":"topic"}]}},"type":"n8n-nodes-base.executeWorkflowTrigger","typeVersion":1.1,"position":[0,0],"id":"72c4ae4a-388d-44fd-b6b2-2bbc7f01a4ad","name":"When Executed by Another Workflow"}],"connections":{"When Executed by Another Workflow":{"main":[[{"node":"ROS2WebInterface Request","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":null,"pinData":{},"versionId":"498f5563-aa2f-4689-9c2a-4434c7a63846","triggerCount":0,"tags":[]},{"createdAt":"2025-04-02T08:34:44.186Z","updatedAt":"2025-04-03T10:30:13.000Z","id":"7ZL6BqrAz65dyBRu","name":"get_ros2_camera_data","active":false,"nodes":[{"parameters":{"url":"http://192.168.6.120:8000/get_data","sendQuery":true,"queryParameters":{"parameters":[{"name":"topic","value":"={{ $json.topic }}"}]},"options":{"timeout":10000}},"id":"4b6878ec-8f9d-4d3c-a2a1-088b44a578e5","name":"ROS2WebInterface Request","type":"n8n-nodes-base.httpRequest","typeVersion":4.1,"position":[40,-20]},{"parameters":{"setAllData":false,"options":{"encoding":"base64"}},"id":"ec8caea5-120f-4fb7-9627-7d97c57004b0","name":"Move Binary Data","type":"n8n-nodes-base.moveBinaryData","typeVersion":1,"position":[280,-20]},{"parameters":{"workflowInputs":{"values":[{"name":"topic"},{"name":"vlm_message"}]}},"type":"n8n-nodes-base.executeWorkflowTrigger","typeVersion":1.1,"position":[-300,-20],"id":"d8592785-2069-46c4-8b0b-ef662ef8befa","name":"When Executed by Another Workflow"},{"parameters":{"method":"POST","url":"http://192.168.6.120:11434/v1/chat/completions","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={\n  \"model\": \"gemma3:27b\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"{{ $json.vlm_system_message }}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"{{ $('When Executed by Another Workflow').item.json.vlm_message }}\"\n        },\n        {\n          \"type\": \"image_url\",\n          \"image_url\": {\n            \"url\": \"data:image/jpeg;base64,{{ $('Move Binary Data').item.json.data }}\"\n          }\n        }\n      ]\n    }\n  ]\n}\n","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.2,"position":[740,-20],"id":"3ead10db-3a78-492d-87e1-6cd9b7fffb6e","name":"HTTP Request"},{"parameters":{"operation":"write","fileName":"/tmp/robot_image","options":{}},"type":"n8n-nodes-base.readWriteFile","typeVersion":1,"position":[240,200],"id":"f60249b8-16e8-4f66-a121-c5e2248adb0d","name":"Read/Write Files from Disk"},{"parameters":{},"type":"n8n-nodes-base.merge","typeVersion":3.1,"position":[960,100],"id":"7df52f2f-b064-4e24-9726-9a3a7cde9802","name":"Merge"},{"parameters":{"aggregate":"aggregateAllItemData","options":{}},"type":"n8n-nodes-base.aggregate","typeVersion":1,"position":[1180,100],"id":"f7c037a2-d631-43eb-81e8-954b703bd037","name":"Aggregate"},{"parameters":{"assignments":{"assignments":[{"id":"c7abcaa6-1393-4412-a478-0263dbe0962c","name":"content","value":"={{ $json.data[0].choices[0].message.content }}","type":"string"},{"id":"e968ae0a-b93e-4434-a3b3-ef4a14042d03","name":"fileName","value":"={{ $json.data[1].fileName }}","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[1400,100],"id":"e2435f96-46d9-4d13-ae2c-06258332679b","name":"Edit Fields"},{"parameters":{"assignments":{"assignments":[{"id":"92a53d2a-37c3-4c72-8819-442b8bb82ff1","name":"vlm_system_message","value":"You are a Vision-Language Model that analyzes images from industrial environments such as factories and power plants. Your task is to produce a detailed, objective description of the image. Your output is not a final answer, but a factual summary that helps another AI agent evaluate safety and detect hazards.","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[520,-20],"id":"60714e2b-7e55-4799-8733-b47d5b9df53e","name":"VLM System Message","alwaysOutputData":false}],"connections":{"ROS2WebInterface Request":{"main":[[{"node":"Move Binary Data","type":"main","index":0},{"node":"Read/Write Files from Disk","type":"main","index":0}]]},"Move Binary Data":{"main":[[{"node":"VLM System Message","type":"main","index":0}]]},"When Executed by Another Workflow":{"main":[[{"node":"ROS2WebInterface Request","type":"main","index":0}]]},"HTTP Request":{"main":[[{"node":"Merge","type":"main","index":0}]]},"Read/Write Files from Disk":{"main":[[{"node":"Merge","type":"main","index":1}]]},"Merge":{"main":[[{"node":"Aggregate","type":"main","index":0}]]},"Aggregate":{"main":[[{"node":"Edit Fields","type":"main","index":0}]]},"VLM System Message":{"main":[[{"node":"HTTP Request","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":null,"pinData":{"When Executed by Another Workflow":[{"json":{"topic":"/timon/camera/hand/image","vlm_message":"Please analyze this image for any potential hazards: helmets or tools on the floor, open or unsecured manholes, ladders or obstructions in walkways, broken safety barriers or fences, or damaged machinery or equipment."}}]},"versionId":"178f0f9c-7e22-4227-aa23-61309c2417ab","triggerCount":0,"tags":[]}]