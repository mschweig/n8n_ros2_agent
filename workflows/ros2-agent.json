[{"createdAt":"2025-04-02T08:34:18.193Z","updatedAt":"2025-04-06T09:17:45.000Z","id":"aY5NYuSO6A1cH9rX","name":"ros2-agent","active":false,"nodes":[{"parameters":{"options":{}},"type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.1,"position":[-440,60],"id":"0fd682cb-1bd7-4a16-9c2c-e2a2235a3a21","name":"When chat message received","webhookId":"971b0b62-a5df-4cd4-b9b2-ef271823f937"},{"parameters":{"sessionIdType":"customKey","sessionKey":"={{ $('When chat message received').item.json.sessionId }}"},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[60,280],"id":"cd9f62d1-83e8-4916-ac4c-c80e075ea697","name":"Simple Memory"},{"parameters":{"name":"ros2_get_camera_data","description":"Call this tool to get an image from the specified robot and query the VLM for analysis.","workflowId":{"__rl":true,"value":"7ZL6BqrAz65dyBRu","mode":"list","cachedResultName":"ros2_get_camera_data"},"workflowInputs":{"mappingMode":"defineBelow","value":{"topic":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('topic', ``, 'string') }}","vlm_message":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('vlm_message', ``, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"topic","displayName":"topic","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"vlm_message","displayName":"vlm_message","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[360,240],"id":"8724aa9f-423f-48fc-b076-4eeb4a4e8061","name":"ROS2 Image Tool"},{"parameters":{"name":"ros2_get_data","description":"Call this tool to get a topic data from the specified robot. You have to provide a robot name and topic name. wifi, power_states, foot, system_faults and so on.\n\n**Call \"ros2_system_tool\" before to get the services, topics and nodes**\n","workflowId":{"__rl":true,"value":"X42iNV4VrvoMTCSX","mode":"list","cachedResultName":"ros2_get_data"},"workflowInputs":{"mappingMode":"defineBelow","value":{"topic":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('topic', ``, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"topic","displayName":"topic","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[200,240],"id":"b99539bd-5ce3-4031-83d3-bdd68a0b81c1","name":"ROS2 Data Tool"},{"parameters":{"promptType":"define","text":"={{ $('When chat message received').item.json.chatInput }}\n\n{{ $json.spot_context }}","options":{"systemMessage":"=# 🤖 AI Agent Context: Industrial Safety & Hazard Monitoring\n\nYou are an **AI assistant** responsible for **real-time environmental safety monitoring** in an **industrial robotics setting**. You interface with **ROS 2-enabled robots** and analyze surroundings using a **Vision-Language Model (VLM)**.\n\nYour mission:  \n⚠️ **Detect and report hazards or dangerous situations.**\n\n---\n\n## 🛠️ Core Responsibilities\n\n- Access live robot data via **ROS 2 topics**\n- Analyze visual feeds using the **VLM** to detect:\n  - Helmets or tools left on the floor  \n  - Open or unsecured manholes  \n  - Ladders or obstructions blocking walkways  \n  - Broken safety barriers or fences  \n  - Damaged or malfunctioning equipment  \n- Respond with **clear, concise safety insights**  \n  → _Example: “Hazard detected: ladder blocking walkway near robot.”_\n\n---\n\n## 🧠 AI Capabilities\n\n- Understand and generate valid **ROS 2 topics and service calls**\n- Query robot **status**, such as battery level, Wi-Fi connectivity, emergency stop (E-Stop), and foot placement\n- Perform **situational awareness** by combining sensor data and image analysis\n\n---\n\n## ⚙️ Initialization Parameters\n\nBefore issuing commands, ensure you have:\n\n- `robot_name` – Name of the robot (e.g., `\"spot\"`, `\"luna\"`, `\"timon\"`, `\"energydog\"`)\n\n- `camera_name` – Camera identifier or topic (e.g., `\"frontleft\"`, `\"hand\"`)  \n  → Only required for **image-based queries**\n\n> ✅ Both must be lowercase.  \n> You only need `camera_name` when analyzing visual data.\n\n**🛑 The agent must always run `/ros2_system_tool list_services` and `/ros2_system_tool list_topics` before any command or query.**  \nWithout this, the agent does not know what services, topics, or nodes are available.\n\n---\n\n## 🧠 Agent Behavior\n\n> 🔍 **Before executing any command or query, always call `/ros2_system_tool` with both**:\n>\n> - `list_services` → to verify the required service exists  \n> - `list_topics` → to confirm the expected topic is available\n>\n> ❗ Only proceed if the target topic or service is present.  \n> This ensures the action is valid and supported by the robot’s current ROS 2 configuration.\n\n---\n\n## 🧰 Tools & ROS 2 Topics\n\n- **`/ros2_system_tool`**  \n  → Used to explore available ROS 2 services, topics, and nodes.  \n  - `/ros2_system_tool list_services` → Lists all available services  \n  - `/ros2_system_tool list_topics` → Lists all available topics  \n  _Must be executed before using any other tool or performing actions._\n\n- **`/ros2_get_camera_data`**  \n  → Topic: `/robot_name/camera/camera_name/image`  \n  → Retrieves an image for visual hazard analysis via VLM.\n\n- **`/ros2_get_data`**  \n  → Topic: `/robot_name/status/<state>`  \n  → Queries robot health and status, such as:\n  - `/robot_name/status/battery_states`\n  - `/robot_name/status/wifi`\n  - `/robot_name/status/estop`\n\n- **`/ros2_call_service`**  \n  → Executes robot actions such as:\n  - `/robot_name/dock`\n  - `/robot_name/undock`\n  - `/robot_name/sit`\n  - `/robot_name/stand`\n\n> ✅ **Always prefix all topics and services with a slash (`/`)**  \n> 🔁 **Always run `/ros2_system_tool list_services` and `/ros2_system_tool list_topics` first**\n\n---\n\n## ✅ Example Interaction\n\n**User:**  \n> Can you check for hazards around `spot` using the `frontright` camera?\n\n**AI Assistant:**  \n> Executing `/ros2_system_tool list_topics` and `/ros2_system_tool list_services` to check availability...  \n> ✅ Topic `/spot/camera/frontright/image` found  \n>  \n> Retrieving image and analyzing with VLM...  \n> _“Warning: tool detected on the floor in front of the robot.”_  \n> _or_  \n> _“No immediate hazards detected.”_"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":1.8,"position":[-20,60],"id":"0a7335f1-943c-4531-a7ad-f782a9dc98d3","name":"VLM Agent"},{"parameters":{"assignments":{"assignments":[{"id":"d2300ad9-d6fb-48e4-b929-33c3a8ed63da","name":"spot_context","value":"# AI Agent Context: Boston Dynamics Spot Robot (ROS 2 Interface)\n\nYou are an AI assistant interfacing with a **Boston Dynamics Spot robot** in an industrial setting. You:\n\n- Communicate via **ROS 2 topics**\n- Query **robot state** (battery, Wi-Fi, E-Stop, etc.)\n- Analyze **camera images** using a **Vision-Language Model (VLM)**\n- Execute **ROS2 services** (undock, dock, sit, stand)\n\n---\n\n## 🔋 Battery States\n\n- 0: Unknown  \n- 1: Missing  \n- 2: Charging  \n- 3: Discharging  \n- 4: Booting\n\n---\n\n## 📶 Wi-Fi Modes\n\n- 0: Unknown  \n- 1: Access Point  \n- 2: Client\n\n---\n\n## 🛑 E-Stop States\n\n- 0: Unknown  \n- 1: Active  \n- 2: Released\n\n---\n\n## ⚙️ Motor Power States\n\n- 0: Unknown  \n- motor_power_state: 1 =  Off — safe to approach  \n- motor_power_state: 2 = On — motors powered  \n- 3: Powering On  \n- 4: Powering Off — not yet safe  \n- 5: Error — must power off before retry\n\n**\"/robot_name/power_off\" and \"/robot_name/power_on\" are used to control the motor power of the robot**\n\n> Note: You might also encounter names like `MOTOR_POWER_STATE_ON` or `STATE_ON`, which have the same values.\n\n---\n\n## 🔌 Shore Power States\n\n- 0: Unknown  \n- 1: On Shore Power — robot is currently charging  \n- 2: Off Shore Power — robot is not charging  \n\n---\n\n## 🧠 Example Interactions\n\n**User:**  \n> What does Spot see with the frontleft camera?  \n→ Topic: `/spot/camera/frontleft/image`  \n→ Tool: `ros2_get_camera_data`\n\n**User:**  \n> What’s luna’s battery status?  \n→ Topic: `/luna/status/battery_states`  \n→ Tool: `ros2_get_data`","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[-200,60],"id":"d57ae0c9-8552-4922-9a8d-7d8d89e0f84d","name":"Spot Robot Context"},{"parameters":{"model":"gpt-4o-mini","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[-80,280],"id":"d03084ac-1ceb-4506-a72d-fa79cb1404d9","name":"Azure OpenAI Chat Model","credentials":{"azureOpenAiApi":{"id":"h0hfKGO6z1Z3QDy2","name":"Azure Open AI account"}}},{"parameters":{"name":"ros2_call_service","description":"Use this tool to execute ROS2 services and actions like robot undocking, docking, sit, stand, arm commands, etc.","workflowId":{"__rl":true,"value":"gq6IDyHyPDCKFEIU","mode":"list","cachedResultName":"ros2_call_service"},"workflowInputs":{"mappingMode":"defineBelow","value":{"topic":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('topic', ``, 'string') }}","body":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('body', `Generate the body for requests that require this field. Such as docking the robot to a specific dock. **For the 'dock' service you need the desired dock_id the robot should dock to. Ask the user if its not specified.\nThis needs to be sent as JSON in POST request body. Example: \\`{\"dock_id\": 520}\\`**`, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"topic","displayName":"topic","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"body","displayName":"body","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[200,380],"id":"7d2c6b44-0a5e-4842-aba9-3a9324d3d236","name":"ROS2 Service Tool"},{"parameters":{"name":"ros2_system_tool","description":"Use this tool to execute ROS2 system commands such as: \nros2 service list, ros2 topic list, ros2 node list. \nWith this tool you can get information about the robots and its functionalities. You need to create the route. \n\nPossible routes are:\n\"list_services\"\n\"list_topics\"\n\"list_nodes\"\n\n**Always execute this tool, to get knowledge about the robot**","workflowId":{"__rl":true,"value":"ybCs9BGpwUo5gNzi","mode":"list","cachedResultName":"ros2_system_tool"},"workflowInputs":{"mappingMode":"defineBelow","value":{"route":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('route', ``, 'string') }}"},"matchingColumns":["topic"],"schema":[{"id":"route","displayName":"route","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false}},"type":"@n8n/n8n-nodes-langchain.toolWorkflow","typeVersion":2.1,"position":[360,380],"id":"1d8b1e23-e449-4e3b-9c88-aa672a365c36","name":"ROS2 System Tool"}],"connections":{"When chat message received":{"main":[[{"node":"Spot Robot Context","type":"main","index":0}]]},"Simple Memory":{"ai_memory":[[{"node":"VLM Agent","type":"ai_memory","index":0}]]},"ROS2 Image Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]},"ROS2 Data Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]},"VLM Agent":{"main":[[]]},"Spot Robot Context":{"main":[[{"node":"VLM Agent","type":"main","index":0}]]},"Azure OpenAI Chat Model":{"ai_languageModel":[[{"node":"VLM Agent","type":"ai_languageModel","index":0}]]},"ROS2 Service Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]},"ROS2 System Tool":{"ai_tool":[[{"node":"VLM Agent","type":"ai_tool","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"b9e22de2-03a9-4fd2-8849-1e95f6d6ff29","triggerCount":0,"tags":[]}]